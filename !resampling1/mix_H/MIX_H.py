import pandas as pd
import os
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

# --- 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Path ---
# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô path ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
folder_path = r'd:\Users\Admin\Desktop\ModelAll\!resampling1\mix_H' 
file1_path = os.path.join(folder_path, 'Merged_AWS_with_PM.csv')
file2_path = os.path.join(folder_path, 'Weather_and_PM_Harry.csv')

output_file_name = 'Combined_Corrected.csv'
output_path = os.path.join(folder_path, output_file_name)

# --- 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô (Robust) ---
def robust_convert(df, filename):
    print(f"\nüîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå: {filename}")
    
    # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó string
    df.columns = df.columns.str.strip()
    if 'Date' in df.columns:
        df['Date'] = df['Date'].astype(str).str.strip()
    if 'Time' in df.columns:
        df['Time'] = df['Time'].astype(str).str.strip()

    # üü¢ Step 1: ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    # errors='coerce' ‡∏à‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡πÄ‡∏ä‡πà‡∏ô 31-09-25) ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô NaT
    date_objs = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')

    # üü¢ Step 2: ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ß‡∏•‡∏≤
    time_objs = pd.to_datetime(df['Time'], errors='coerce')

    # üü¢ Step 3: ‡∏£‡∏ß‡∏°‡∏£‡πà‡∏≤‡∏á (Date + Time)
    # ‡πÉ‡∏ä‡πâ‡∏™‡∏π‡∏ï‡∏£‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    df['DateTime_Sort'] = date_objs + (time_objs - time_objs.dt.normalize())

    # --- ‡πÄ‡∏ä‡πá‡∏Ñ‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏µ‡∏¢ ---
    mask_bad = df['DateTime_Sort'].isna()
    bad_rows_count = mask_bad.sum()
    
    if bad_rows_count > 0:
        print(f"   ‚ö†Ô∏è ‡∏û‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà/‡πÄ‡∏ß‡∏•‡∏≤‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥: {bad_rows_count} ‡πÅ‡∏ñ‡∏ß (‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏•‡∏ö‡∏ó‡∏¥‡πâ‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)")
    else:
        print("   ‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô")

    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡πÄ‡∏™‡∏µ‡∏¢
    df_clean = df[~mask_bad].copy()
    
    # ‡∏à‡∏±‡∏î Format ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (24 ‡∏ä‡∏°.)
    df_clean['Date'] = df_clean['DateTime_Sort'].dt.strftime('%d/%m/%Y')
    df_clean['Time'] = df_clean['DateTime_Sort'].dt.strftime('%H:%M:%S')
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤ PM2.5 ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Ç‡∏¢‡∏∞‡∏õ‡∏ô‡∏°‡∏≤)
    if 'out_pm25' in df_clean.columns:
        df_clean['out_pm25'] = pd.to_numeric(df_clean['out_pm25'], errors='coerce')
    
    return df_clean

try:
    # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå
    print("üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå...")
    df1 = pd.read_csv(file1_path, low_memory=False)
    df2 = pd.read_csv(file2_path, low_memory=False)

    # ‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
    df1_clean = robust_convert(df1, 'Merged_AWS_with_PM.csv')
    df2_clean = robust_convert(df2, 'Weather_and_PM_Harry.csv')

    # ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå
    print("\nüîó ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå...")
    combined_df = pd.concat([df1_clean, df2_clean], ignore_index=True)

    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤
    combined_df = combined_df.sort_values(by='DateTime_Sort')
    
    # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ß‡∏•‡∏≤‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡πÄ‡∏õ‡πä‡∏∞‡πÜ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    combined_df = combined_df.drop_duplicates(subset=['DateTime_Sort'])

    # --- 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå ---
    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏≠‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏ã‡∏ü (‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
    df_to_save = combined_df.drop(columns=['DateTime_Sort'])
    df_to_save.to_csv(output_path, index=False, encoding='utf-8')
    
    print("-" * 40)
    print(f"üéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏µ‡πà: {output_path}")
    print(f"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏´‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏°: {len(combined_df)}")
    print("-" * 40)

    # ========================================================
    # üìà ‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Plotting Section)
    # ========================================================
    print("\nüìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")

    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ
    plt.rcParams['figure.figsize'] = [12, 10]
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≤‡∏ü 2 ‡∏ä‡πà‡∏≠‡∏á (‡∏ö‡∏ô/‡∏•‡πà‡∏≤‡∏á)
    fig, (ax1, ax2) = plt.subplots(2, 1)
    
    # --- ‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà 1: PM2.5 Time Series ---
    # ‡∏û‡∏•‡πá‡∏≠‡∏ï‡∏Ñ‡πà‡∏≤ out_pm25 ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
    plot_data = combined_df.dropna(subset=['out_pm25'])
    ax1.plot(plot_data['DateTime_Sort'], plot_data['out_pm25'], 
             color='#d62728', linewidth=0.8, label='out_pm25')
    
    ax1.set_title('PM2.5 Value Over Time (‡∏Ñ‡πà‡∏≤‡∏ù‡∏∏‡πà‡∏ô PM2.5 ‡∏ï‡∏•‡∏≠‡∏î‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤)', fontsize=14, fontweight='bold')
    ax1.set_ylabel('PM2.5 (¬µg/m¬≥)', fontsize=12)
    ax1.grid(True, linestyle='--', alpha=0.7)
    ax1.legend()
    
    # Format ‡πÅ‡∏Å‡∏ô X
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%y'))
    ax1.xaxis.set_major_locator(mdates.AutoDateLocator())

    # --- ‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà 2: Data Points per Day (Check Gaps) ---
    combined_df['Date_Only'] = combined_df['DateTime_Sort'].dt.date
    daily_counts = combined_df.groupby('Date_Only').size()
    
    ax2.plot(daily_counts.index, daily_counts.values, marker='o', linestyle='-', color='royalblue', markersize=4)
    ax2.set_title('Data Points per Day (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏ô - ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≤‡∏î)', fontsize=14, fontweight='bold')
    ax2.set_ylabel('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß (Rows)', fontsize=12)
    ax2.set_xlabel('‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà (Date)', fontsize=12)
    ax2.grid(True, linestyle='--', alpha=0.7)
    
    # Format ‡πÅ‡∏Å‡∏ô X
    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%y'))
    ax2.xaxis.set_major_locator(mdates.AutoDateLocator())
    plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')
    plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')

    plt.tight_layout()
    plt.show()
    
    print("‚úÖ ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

except Exception as e:
    print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")